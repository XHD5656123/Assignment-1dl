{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Assignment 1: Multi-Layer Perceptron with MNIST Dataset"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this assignment, you are required to train two MLPs to classify images from the [MNIST database](http://yann.lecun.com/exdb/mnist/) hand-written digit database by using PyTorch.\n",
    "\n",
    "The process will be broken down into the following steps:\n",
    ">1. Load and visualize the data.\n",
    "2. Define a neural network. (30 marks)\n",
    "3. Train the models. (30 marks)\n",
    "4. Evaluate the performance of our trained models on the test dataset. (20 marks)\n",
    "5. Analysis your results. (20 marks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch import nn\n",
    "import numpy as np\n",
    "import logging\n",
    "import sys\n",
    "\n",
    "# set log\n",
    "logging.basicConfig(level=logging.INFO,\n",
    "                    format='%(asctime)s %(levelname)s: %(message)s',\n",
    "                     datefmt='%Y-%m-%d %H:%M:%S',)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Get the version information of your package"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-10-11 12:42:00 INFO: The version information:\n",
      "2023-10-11 12:42:00 INFO: Python: 3.9.18 (main, Sep 11 2023, 14:09:26) [MSC v.1916 64 bit (AMD64)]\n",
      "2023-10-11 12:42:00 INFO: PyTorch: 1.12.0\n"
     ]
    }
   ],
   "source": [
    "logging.info('The version information:')\n",
    "logging.info(f'Python: {sys.version}')\n",
    "logging.info(f'PyTorch: {torch.__version__}')\n",
    "assert torch.cuda.is_available() == True, 'Please finish your GPU develop environment'"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## Load and Visualize the Data\n",
    "\n",
    "Downloading may take a few moments, and you should see your progress as the data is loading. You may also choose to change the `batch_size` if you want to load more data at a time.\n",
    "\n",
    "This cell will create DataLoaders for each of our datasets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torchvision import datasets\n",
    "import torchvision.transforms as transforms\n",
    "from torch.utils.data.dataset import Dataset\n",
    "\n",
    "# number of subprocesses to use for data loading\n",
    "num_workers = 0\n",
    "# how many samples per batch to load\n",
    "batch_size = 20\n",
    "\n",
    "# convert data to torch.FloatTensor\n",
    "transform = transforms.ToTensor()\n",
    "\n",
    "# choose the training and test datasets\n",
    "train_data = datasets.MNIST(root='data', train=True,\n",
    "                                   download=True, transform=transform)\n",
    "test_data = datasets.MNIST(root='data', train=False,\n",
    "                                  download=True, transform=transform)\n",
    "\n",
    "# prepare data loaders\n",
    "def classify_label(dataset, num_classes):\n",
    "    list_index = [[] for _ in range(num_classes)]\n",
    "    for idx, datum in enumerate(dataset):\n",
    "        list_index[datum[1]].append(idx)\n",
    "    return list_index\n",
    "\n",
    "def partition_train(list_label2indices: list, num_per_class: int):\n",
    "    random_state = np.random.RandomState(0)\n",
    "    list_label2indices_train = []\n",
    "    for indices in list_label2indices:\n",
    "        random_state.shuffle(indices)\n",
    "        list_label2indices_train.extend(indices[:num_per_class])\n",
    "    return list_label2indices_train\n",
    "\n",
    "class Indices2Dataset(Dataset):\n",
    "    def __init__(self, dataset):\n",
    "        self.dataset = dataset\n",
    "        self.indices = None\n",
    "\n",
    "    def load(self, indices: list):\n",
    "        self.indices = indices\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        idx = self.indices[idx]\n",
    "        image, label = self.dataset[idx]\n",
    "        return image, label\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.indices)\n",
    "\n",
    "#  sort train data by label\n",
    "list_label2indices = classify_label(dataset=train_data, num_classes=10)\n",
    "\n",
    "# how many samples per class to train\n",
    "list_train = partition_train(list_label2indices, 500)\n",
    "\n",
    "# prepare data loaders  \n",
    "indices2data = Indices2Dataset(train_data)\n",
    "indices2data.load(list_train)\n",
    "train_loader = torch.utils.data.DataLoader(indices2data, batch_size=batch_size, num_workers=num_workers, shuffle=True)\n",
    "test_loader = torch.utils.data.DataLoader(test_data, batch_size=batch_size, num_workers=num_workers, shuffle=True)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Visualize a Batch of Training Data\n",
    "\n",
    "The first step in a classification task is to take a look at the data, make sure it is loaded in correctly, then make any initial observations about patterns in that data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m在当前单元格或上一个单元格中执行代码时 Kernel 崩溃。请查看单元格中的代码，以确定故障的可能原因。有关详细信息，请单击 <a href='https://aka.ms/vscodeJupyterKernelCrash'>此处</a>。有关更多详细信息，请查看 Jupyter <a href='command:jupyter.viewOutput'>log</a>。"
     ]
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline  \n",
    "\n",
    "# obtain one batch of training images\n",
    "dataiter = iter(train_loader)\n",
    "images, labels = dataiter.next()\n",
    "images = images.numpy()\n",
    "\n",
    "# plot the images in the batch, along with the corresponding labels\n",
    "fig = plt.figure(figsize=(25, 4))\n",
    "for idx in np.arange(20):\n",
    "    ax = fig.add_subplot(2, 20//2, idx+1, xticks=[], yticks=[])\n",
    "    ax.imshow(np.squeeze(images[idx]), cmap='gray')\n",
    "    # print out the correct label for each image\n",
    "    # .item() gets the value contained in a Tensor\n",
    "    ax.set_title(str(labels[idx].item()))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### View an Image in More Detail"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'np' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32mf:\\OneDrive\\课\\深度学习\\lecture4 attachment\\Assignment 1.ipynb 单元格 11\u001b[0m line \u001b[0;36m1\n\u001b[1;32m----> <a href='vscode-notebook-cell:/f%3A/OneDrive/%E8%AF%BE/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/lecture4%20attachment/Assignment%201.ipynb#X13sZmlsZQ%3D%3D?line=0'>1</a>\u001b[0m img \u001b[39m=\u001b[39m np\u001b[39m.\u001b[39msqueeze(images[\u001b[39m1\u001b[39m])\n\u001b[0;32m      <a href='vscode-notebook-cell:/f%3A/OneDrive/%E8%AF%BE/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/lecture4%20attachment/Assignment%201.ipynb#X13sZmlsZQ%3D%3D?line=2'>3</a>\u001b[0m fig \u001b[39m=\u001b[39m plt\u001b[39m.\u001b[39mfigure(figsize \u001b[39m=\u001b[39m (\u001b[39m12\u001b[39m,\u001b[39m12\u001b[39m)) \n\u001b[0;32m      <a href='vscode-notebook-cell:/f%3A/OneDrive/%E8%AF%BE/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/lecture4%20attachment/Assignment%201.ipynb#X13sZmlsZQ%3D%3D?line=3'>4</a>\u001b[0m ax \u001b[39m=\u001b[39m fig\u001b[39m.\u001b[39madd_subplot(\u001b[39m111\u001b[39m)\n",
      "\u001b[1;31mNameError\u001b[0m: name 'np' is not defined"
     ]
    }
   ],
   "source": [
    "img = np.squeeze(images[1])\n",
    "\n",
    "fig = plt.figure(figsize = (12,12)) \n",
    "ax = fig.add_subplot(111)\n",
    "ax.imshow(img, cmap='gray')\n",
    "width, height = img.shape\n",
    "thresh = img.max()/2.5\n",
    "for x in range(width):\n",
    "    for y in range(height):\n",
    "        val = round(img[x][y],2) if img[x][y] !=0 else 0\n",
    "        ax.annotate(str(val), xy=(y,x),\n",
    "                    horizontalalignment='center',\n",
    "                    verticalalignment='center',\n",
    "                    color='white' if img[x][y]<thresh else 'black')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## Set random seed\n",
    "A random seed is used to ensure that results are reproducible. In other words, using this parameter makes sure that anyone who re-runs your code will get the exact same outputs. Reproducibility is an extremely important concept in data science and other fields. More details to read: [How to Use Random Seeds Effectively](https://towardsdatascience.com/how-to-use-random-seeds-effectively-54a4cd855a79)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-10-10 23:14:38 INFO: tha value of the random seed: 2023\n"
     ]
    }
   ],
   "source": [
    "import random\n",
    "import os\n",
    "\n",
    "## give the number you like such as 2023\n",
    "seed_value = 2023\n",
    "\n",
    "np.random.seed(seed_value)\n",
    "random.seed(seed_value)\n",
    "os.environ['PYTHONHASHSEED'] = str(seed_value)\n",
    "\n",
    "torch.manual_seed(seed_value)     \n",
    "torch.cuda.manual_seed(seed_value)     \n",
    "torch.cuda.manual_seed_all(seed_value)   \n",
    "torch.backends.cudnn.deterministic = True\n",
    "logging.info(f\"tha value of the random seed: {seed_value}\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## Define the Network Architecture (30 marks)\n",
    "\n",
    "* Input: a 784-dim Tensor of pixel values for each image.\n",
    "* Output: a 10-dim Tensor of number of classes that indicates the class scores for an input image. \n",
    "\n",
    "You need to implement three models:\n",
    "1. a vanilla multi-layer perceptron. (10 marks)\n",
    "2. a multi-layer perceptron with regularization (dropout or L2 or both). (10 marks)\n",
    "3. the corresponding loss functions and optimizers. (10 marks)\n",
    "\n",
    "## 定义网络结构（30 分）\n",
    "\n",
    "* 输入：每幅图像像素值的 784 维张量。\n",
    "* 输出：表示输入图像类别得分的 10 维类别数张量。\n",
    "\n",
    "您需要实现三种模型：\n",
    "1. 香草多层感知器。(10 分）\n",
    "2. 带正则化（滤除或 L2 或两者）的多层感知器。(10 分）\n",
    "3. 相应的损失函数和优化器。(10 分）"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Build model_1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Define the MLP architecture\n",
    "class VanillaMLP(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(VanillaMLP, self).__init__()\n",
    "        \n",
    "        # implement your codes here\n",
    "        #D_in,H,D_out = 784,100,10\n",
    "        self.linear1 = torch.nn.Linear(784,100)\n",
    "        self.linear2 = torch.nn.Linear(100,10)#need two MLPs to classify images\n",
    "        \n",
    "\n",
    "\n",
    "    def forward(self, x):\n",
    "        # flatten image input\n",
    "        x = x.view(-1, 28 * 28) #view ()相当于reshape、resize，重新调整Tensor的形状,-1表示不确定的数\n",
    "\n",
    "\n",
    "        # implement your codes here\n",
    "        h_relu = self.linear1(x).clamp(min=0)\n",
    "        x = self.linear2(h_relu)\n",
    "        \n",
    "        \n",
    "        return x\n",
    "\n",
    "# initialize the MLP\n",
    "model_1 = VanillaMLP()\n",
    "\n",
    "# specify loss function\n",
    "# implement your codes here\n",
    "loss_model_1 = torch.nn.Softmax() #十分类任务\n",
    "\n",
    "# specify your optimizer\n",
    "# implement your codes here\n",
    "optimizer_model_1 = torch.optim.SGD(model_1.parameters(),lr=1e-4)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Build model_2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Define the MLP architecture\n",
    "class RegularizedMLP(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(RegularizedMLP, self).__init__()\n",
    "        \n",
    "        # implement your codes here\n",
    "        self.layer1 = torch.nn.Sequential(\n",
    "            \n",
    "            nn.Linear(784,100),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(0.5))\n",
    "        self.layer2 =  torch.nn.Sequential(\n",
    "            \n",
    "            nn.Linear(784,100),\n",
    "            nn.ReLU(), \n",
    "            nn.BatchNorm2d(0.00001))\n",
    "\n",
    "    def forward(self, x):\n",
    "        # flatten image input\n",
    "        x = x.view(-1, 28 * 28)\n",
    "\n",
    "        # implement your codes here\n",
    "        x = self.layer1(x)\n",
    "        x = self.layer2(x)\n",
    "        \n",
    "        return x\n",
    "\n",
    "\n",
    "# initialize the MLP\n",
    "model_2 = RegularizedMLP()\n",
    "\n",
    "# specify loss function\n",
    "# implement your codes here\n",
    "loss_model_2 = torch.nn.Softmax(dim=1)\n",
    "\n",
    "# specify your optimizer\n",
    "# implement your codes here\n",
    "optimizer_model_2 = torch.optim(model_2.parameters(),lr=1e-4)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## Train the Network (30 marks)\n",
    "\n",
    "Train your models in the following two cells.\n",
    "\n",
    "The following loop trains for 30 epochs; feel free to change this number. For now, we suggest somewhere between 20-50 epochs. As you train, take a look at how the values for the training loss decrease over time. We want it to decrease while also avoiding overfitting the training data. \n",
    "\n",
    "We will introduce some metrics of classification tasks and you will learn how implement these metrics with scikit-learn.\n",
    "\n",
    "There are supply some references for you to learn: [evaluation_metrics_spring2020](https://cs229.stanford.edu/section/evaluation_metrics_spring2020.pdf).\n",
    "\n",
    "In training processing, we will use accuracy,  Area Under ROC and top k accuracy.\n",
    "\n",
    "**The key parts in the training process are left for you to implement.**"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train model_1\n",
    "#### Train model_1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import scikit-learn packages\n",
    "# please use the function imported from scikit-learn to metric the process of training of the model\n",
    "from sklearn.metrics import accuracy_score,roc_auc_score, top_k_accuracy_score\n",
    "# number of epochs to train the model\n",
    "n_epochs = 20  # suggest training between 20-50 epochs\n",
    "\n",
    "model_1.train() # prep model for training\n",
    "\n",
    "train_loss_list = []\n",
    "train_acc_list = []\n",
    "train_auc_list = []\n",
    "train_top_k_acc_list = []\n",
    "\n",
    "\n",
    "# GPU check\n",
    "logging.info(f'GPU is available: {torch.cuda.is_available()}')\n",
    "if torch.cuda.is_available():\n",
    "    gpu_num = torch.cuda.device_count()\n",
    "    logging.info(f\"Train model on {gpu_num} GPUs:\")\n",
    "    for i in range(gpu_num):\n",
    "        print('\\t GPU {}.: {}'.format(i,torch.cuda.get_device_name(i)))\n",
    "    model_1 = model_1.cuda()\n",
    "\n",
    "for epoch in range(n_epochs):\n",
    "    # monitor training loss\n",
    "    train_loss = 0.0\n",
    "    pred_array = None\n",
    "    label_array =  None\n",
    "    \n",
    "    one_hot_label_matrix = None\n",
    "    pred_matrix = None\n",
    "    \n",
    "\n",
    "    for data, label in train_loader:\n",
    "        data = data.cuda()\n",
    "        label = label.cuda()\n",
    "        # implement your code here\n",
    "        train_loss += loss_model_1 #这里肯定是算loss\n",
    "        \n",
    "\n",
    "        # finish the the computation of variables of metric\n",
    "        # implement your codes here\n",
    "        if pred_matrix is None:\n",
    "            pred_matrix = model_1(data) #pred images, labels(data)list_train\n",
    "        else:\n",
    "            pred_matrix = np.concatenate() # 把矩阵合并成一整个矩阵\n",
    "\n",
    "        if one_hot_label_matrix is None:\n",
    "            one_hot_label_matrix = torch.scatter(model_1(label),1,) #这应该放真实的样本标签 groundtruth，应该是去数据集取的吧\n",
    "        else:\n",
    "            one_hot_label_matrix = np.concatenate()\n",
    "\n",
    "        pred = torch.argmax(pred, axis=1) #返回指定维度最大值的序号\n",
    "        if pred_array is None:\n",
    "            pred_array = pred_matrix(pred)#   想要从训练中的model1取出最大的预测值 pred\n",
    "        else:\n",
    "            pred_array = np.concatenate()\n",
    "\n",
    "        if label_array is None:\n",
    "            label_array = one_hot_label_matrix(pred)#\n",
    "        else:\n",
    "            label_array = np.concatenate()\n",
    "\n",
    "        \n",
    "\n",
    "\n",
    "        \n",
    "        \n",
    "    # print training statistics \n",
    "    # read the API document at https://scikit-learn.org/stable/modules/classes.html#module-sklearn.metrics to finish your code\n",
    "    # don't craft your own code\n",
    "    # calculate average loss and accuracy over an epoch\n",
    "    \n",
    "    top_k = 3\n",
    "    train_loss = train_loss / len(train_loader.dataset)\n",
    "    train_acc = 100. * accuracy_score(label_array, pred_array) #label_array, pred_array对应值，对得上对不上\n",
    "    train_auc = roc_auc_score(one_hot_label_matrix, pred_matrix , multi_class='ovo')  #pred_matrix\n",
    "    #one_hot_label_matrix shape (n_samples, n_classes).\n",
    "    top_k_acc = top_k_accuracy_score(label_array, pred_matrix , k=top_k,)\n",
    "    # append the value of the metric to the list\n",
    "    train_loss_list.append(train_loss.cpu().detach().numpy())\n",
    "    train_acc_list.append(train_acc)\n",
    "    train_auc_list.append(train_auc)\n",
    "    train_top_k_acc_list.append(top_k_acc)\n",
    "    \n",
    "    logging.info('Epoch: {} \\tTraining Loss: {:.6f} \\tTraining Acc: {:.2f}% \\t top {} Acc: {:.2f}% \\t AUC Score: {:.4f}'.format(\n",
    "        epoch+1, \n",
    "        train_loss,\n",
    "        train_acc,\n",
    "        top_k,\n",
    "        top_k_acc,\n",
    "        train_auc,\n",
    "        ))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Visualize the training process of the model_1\n",
    "Please read the [document](https://matplotlib.org/stable/tutorials/introductory/pyplot.html#sphx-glr-tutorials-introductory-pyplot-py) to finish the training process visualization.\n",
    "For more information, please refer to the [document](https://matplotlib.org/stable/tutorials/index.html)\n",
    "##### Plot the change of the loss of model_1 during training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "epochs_list = list(range(1,n_epochs+1))\n",
    "plt.figure(figsize=(20, 8))\n",
    "plt.plot(epochs_list, train_loss_list)\n",
    "plt.title('Model_1 loss')\n",
    "plt.ylabel('Loss')\n",
    "plt.xlabel('Epoch')\n",
    "plt.legend(['Train'], loc='upper right')\n",
    "plt.show()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Plot the change of the accuracy of model_1 during training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(20, 8))\n",
    "plt.plot(epochs_list, train_acc_list)\n",
    "plt.title('Model_1 accuracy')\n",
    "plt.ylabel('accuracy')\n",
    "plt.xlabel('Epoch')\n",
    "plt.legend(['Train'], loc='upper right')\n",
    "plt.show()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Plot the change of the AUC Score of model_1 during training\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(20, 8))\n",
    "plt.plot(epochs_list, train_auc_list)\n",
    "plt.title('Model_1 auc')\n",
    "plt.ylabel('Auc')\n",
    "plt.xlabel('Epoch')\n",
    "plt.legend(['Train'], loc='upper right')\n",
    "plt.show()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train model_2\n",
    "\n",
    "#### Train model_2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import scikit-learn packages\n",
    "# please use the function imported from scikit-learn to metric the process of training of the model\n",
    "from sklearn.metrics import accuracy_score,roc_auc_score, top_k_accuracy_score\n",
    "# number of epochs to train the model\n",
    "n_epochs = 20  # suggest training between 20-50 epochs\n",
    "\n",
    "model_1.train() # prep model for training\n",
    "\n",
    "train_loss_list = []\n",
    "train_acc_list = []\n",
    "train_auc_list = []\n",
    "train_top_k_acc_list = []\n",
    "\n",
    "\n",
    "# GPU check\n",
    "logging.info(f'GPU is available: {torch.cuda.is_available()}')\n",
    "if torch.cuda.is_available():\n",
    "    gpu_num = torch.cuda.device_count()\n",
    "    logging.info(f\"Train model on {gpu_num} GPUs:\")\n",
    "    for i in range(gpu_num):\n",
    "        print('\\t GPU {}.: {}'.format(i,torch.cuda.get_device_name(i)))\n",
    "    model_1 = model_1.cuda()\n",
    "\n",
    "for epoch in range(n_epochs):\n",
    "    # monitor training loss\n",
    "    train_loss = 0.0\n",
    "    pred_array = None\n",
    "    label_array =  None\n",
    "    \n",
    "    one_hot_label_matrix = None\n",
    "    pred_matrix = None\n",
    "    \n",
    "\n",
    "    for data, label in train_loader:\n",
    "        data = data.cuda()\n",
    "        label = label.cuda()\n",
    "        # implement your code here\n",
    "        \n",
    "\n",
    "        # finish the the computation of variables of metric\n",
    "        # implement your codes here\n",
    "        if pred_matrix is None:\n",
    "            pred_matrix = \n",
    "        else:\n",
    "            pred_matrix = np.concatenate()\n",
    "\n",
    "        if one_hot_label_matrix is None:\n",
    "            one_hot_label_matrix = \n",
    "        else:\n",
    "            one_hot_label_matrix = np.concatenate()\n",
    "\n",
    "        pred = torch.argmax(pred, axis=1)\n",
    "        if pred_array is None:\n",
    "            pred_array = \n",
    "        else:\n",
    "            pred_array = np.concatenate()\n",
    "\n",
    "        if label_array is None:\n",
    "            label_array = \n",
    "        else:\n",
    "            label_array = np.concatenate()\n",
    "\n",
    "        \n",
    "\n",
    "\n",
    "        \n",
    "        \n",
    "    # print training statistics \n",
    "    # read the API document at https://scikit-learn.org/stable/modules/classes.html#module-sklearn.metrics to finish your code\n",
    "    # don't craft your own code\n",
    "    # calculate average loss and accuracy over an epoch\n",
    "    \n",
    "    top_k = 3\n",
    "    train_loss = train_loss / len(train_loader.dataset)\n",
    "    train_acc = 100. * accuracy_score(label_array, pred_array)\n",
    "    train_auc = roc_auc_score(one_hot_label_matrix, pred_matrix , multi_class='ovo')\n",
    "    top_k_acc = top_k_accuracy_score(label_array, pred_matrix , k=top_k,)\n",
    "    # append the value of the metric to the list\n",
    "    train_loss_list.append(train_loss.cpu().detach().numpy())\n",
    "    train_acc_list.append(train_acc)\n",
    "    train_auc_list.append(train_auc)\n",
    "    train_top_k_acc_list.append(top_k_acc)\n",
    "    \n",
    "    logging.info('Epoch: {} \\tTraining Loss: {:.6f} \\tTraining Acc: {:.2f}% \\t top {} Acc: {:.2f}% \\t AUC Score: {:.4f}'.format(\n",
    "        epoch+1, \n",
    "        train_loss,\n",
    "        train_acc,\n",
    "        top_k,\n",
    "        top_k_acc,\n",
    "        train_auc,\n",
    "        ))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Visualize the training process of the model_2\n",
    "Please read the [document](https://matplotlib.org/stable/tutorials/introductory/pyplot.html#sphx-glr-tutorials-introductory-pyplot-py) to finish the training process visualization.\n",
    "For more information, please refer to the [document](https://matplotlib.org/stable/tutorials/index.html)\n",
    "##### Plot the change of the loss of model_2 during training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "epochs_list = list(range(1,n_epochs+1))\n",
    "plt.figure(figsize=(20, 8))\n",
    "plt.plot(epochs_list, train_loss_list)\n",
    "plt.title('Model_2 loss')\n",
    "plt.ylabel('Loss')\n",
    "plt.xlabel('Epoch')\n",
    "plt.legend(['Train'], loc='upper right')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Plot the change of the accuracy of model_2 during training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(20, 8))\n",
    "plt.plot(epochs_list, train_acc_list)\n",
    "plt.title('Model_2 accuracy')\n",
    "plt.ylabel('accuracy')\n",
    "plt.xlabel('Epoch')\n",
    "plt.legend(['Train'], loc='upper right')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Plot the change of the AUC Score of model_1 during training\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(20, 8))\n",
    "plt.plot(epochs_list, train_auc_list)\n",
    "plt.title('Model_2 auc')\n",
    "plt.ylabel('Auc')\n",
    "plt.xlabel('Epoch')\n",
    "plt.legend(['Train'], loc='upper right')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## Test the Trained Network (20 marks)\n",
    "\n",
    "Test the performance of trained models on test data. Except the total test accuracy, you should calculate the accuracy for each class.\n",
    "\n",
    "About metrics, in test processing, we will use accuracy, top k accuracy, precision, recall, f1-score and confusion matrix. \n",
    "\n",
    "Besides, we will visualize the confusion matrix.\n",
    "\n",
    "Last but not least, we will compare your implementation of function to compute accuracy with the implementation of scikit-learn."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## define your implementation of function to compute accuracy\n",
    "def accuracy_score_manual(label_array, pred_array):\n",
    "    # implement your codes here"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test model_1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import classification_report,ConfusionMatrixDisplay\n",
    "# initialize lists to monitor test loss and accuracy\n",
    "test_loss = 0.0\n",
    "\n",
    "pred_array = None\n",
    "label_array =  None\n",
    "\n",
    "one_hot_label_matrix = None\n",
    "pred_matrix = None\n",
    "\n",
    "model_1.eval() # prep model for *evaluation*\n",
    "\n",
    "for data, label in test_loader:\n",
    "    data = data.cuda()\n",
    "    label = label.cuda()\n",
    "    # implement your code here\n",
    "    pred = \n",
    "    test_loss = \n",
    "\n",
    "    if pred_matrix is None:\n",
    "        pred_matrix = \n",
    "    else:\n",
    "        pred_matrix = \n",
    "\n",
    "    if one_hot_label_matrix is None:\n",
    "        one_hot_label_matrix = \n",
    "    else:\n",
    "        one_hot_label_matrix = \n",
    "    pred = torch.argmax(pred, axis=1)\n",
    "    \n",
    "    if pred_array is None:\n",
    "        pred_array = \n",
    "    else:\n",
    "        pred_array = \n",
    "\n",
    "    if label_array is None:\n",
    "        label_array = \n",
    "    else:\n",
    "        label_array = \n",
    "# calculate and print avg test loss\n",
    "test_loss = test_loss / len(test_loader.dataset)\n",
    "test_acc = accuracy_score(label_array, pred_array)\n",
    "test_auc = roc_auc_score(one_hot_label_matrix, pred_matrix , multi_class='ovo')\n",
    "test_top_k3_acc = top_k_accuracy_score(label_array, pred_matrix , k=3)\n",
    "test_top_k5_acc = top_k_accuracy_score(label_array, pred_matrix , k=5)\n",
    "\n",
    "logging.info('Test Loss: {:.6f}'.format(test_loss))\n",
    "logging.info('Test Accuracy: {:.6f}'.format(test_acc))\n",
    "logging.info('Test top 3 Accuracy: {:.6f}'.format(test_top_k3_acc ))\n",
    "logging.info('Test top 5 Accuracy: {:.6f}'.format(test_top_k5_acc ))\n",
    "logging.info('The classification report of test for model_1')\n",
    "print(classification_report(label_array, pred_array))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ConfusionMatrixDisplay.from_predictions(label_array,pred_array)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## compare your implementation of function to compute accuracy with the implementation of scikit-learn.\n",
    "your_test_acc = accuracy_score_manual(label_array, pred_array)\n",
    "assert abs(your_test_acc - test_acc) < 1e-5 , 'Please check your implementation of function to compute accuracy'"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test model_2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import classification_report,ConfusionMatrixDisplay\n",
    "# initialize lists to monitor test loss and accuracy\n",
    "test_loss = 0.0\n",
    "\n",
    "pred_array = None\n",
    "label_array =  None\n",
    "\n",
    "one_hot_label_matrix = None\n",
    "pred_matrix = None\n",
    "\n",
    "model_2.eval() # prep model for *evaluation*\n",
    "\n",
    "for data, label in test_loader:\n",
    "    data = data.cuda()\n",
    "    label = label.cuda()\n",
    "    # implement your code here\n",
    "    pred = \n",
    "    test_loss = \n",
    "\n",
    "    if pred_matrix is None:\n",
    "        pred_matrix = \n",
    "    else:\n",
    "        pred_matrix = \n",
    "\n",
    "    if one_hot_label_matrix is None:\n",
    "        one_hot_label_matrix = \n",
    "    else:\n",
    "        one_hot_label_matrix = \n",
    "    pred = torch.argmax(pred, axis=1)\n",
    "    \n",
    "    if pred_array is None:\n",
    "        pred_array = \n",
    "    else:\n",
    "        pred_array = \n",
    "\n",
    "    if label_array is None:\n",
    "        label_array = \n",
    "    else:\n",
    "        label_array = \n",
    "# calculate and print avg test loss\n",
    "test_loss = test_loss / len(test_loader.dataset)\n",
    "test_acc = accuracy_score(label_array, pred_array)\n",
    "test_auc = roc_auc_score(one_hot_label_matrix, pred_matrix , multi_class='ovo') #one_hot_label_matrix ytrue\n",
    "test_top_k3_acc = top_k_accuracy_score(label_array, pred_matrix , k=3)\n",
    "test_top_k5_acc = top_k_accuracy_score(label_array, pred_matrix , k=5)\n",
    "\n",
    "logging.info('Test Loss: {:.6f}'.format(test_loss))\n",
    "logging.info('Test Accuracy: {:.6f}'.format(test_acc))\n",
    "logging.info('Test top 3 Accuracy: {:.6f}'.format(test_top_k3_acc ))\n",
    "logging.info('Test top 5 Accuracy: {:.6f}'.format(test_top_k5_acc ))\n",
    "logging.info('The classification report of test for model_1')\n",
    "print(classification_report(label_array, pred_array))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ConfusionMatrixDisplay.from_predictions(label_array,pred_array)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## compare your implementation of function to compute accuracy with the implementation of scikit-learn.\n",
    "your_test_acc = accuracy_score_manual(label_array, pred_array)\n",
    "assert abs(your_test_acc - test_acc) < 1e-5 , 'Please check your implementation of function to compute accuracy'"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## Analyze Your Result (20 marks)\n",
    "Compare the performance of your models with the following analysis. Both English and Chinese answers are acceptable.\n",
    "1. Does your vanilla MLP overfit to the training data? (5 marks)你的香草MLP是否与训练数据过拟合?\n",
    "\n",
    "Answer:\n",
    "\n",
    "2. If yes, how do you observe it? If no, why? (5 marks)如果是，如何观察?如果没有，为什么?\n",
    "\n",
    "Answer:\n",
    "\n",
    "3. Is regularized model help prevent overfitting? (5 marks)正则化模型是否有助于防止过拟合\n",
    "\n",
    "Answer:\n",
    "\n",
    "4. Generally compare the performance of two models. (5 marks)比较两种型号的性能\n",
    "\n",
    "Answer:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
