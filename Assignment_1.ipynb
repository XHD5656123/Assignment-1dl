{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Assignment 1: Multi-Layer Perceptron with MNIST Dataset"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this assignment, you are required to train two MLPs to classify images from the [MNIST database](http://yann.lecun.com/exdb/mnist/) hand-written digit database by using PyTorch.\n",
    "\n",
    "The process will be broken down into the following steps:\n",
    ">1. Load and visualize the data.\n",
    "2. Define a neural network. (30 marks)\n",
    "3. Train the models. (30 marks)\n",
    "4. Evaluate the performance of our trained models on the test dataset. (20 marks)\n",
    "5. Analysis your results. (20 marks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch import nn\n",
    "import numpy as np\n",
    "import logging\n",
    "import sys\n",
    "\n",
    "# set log\n",
    "logging.basicConfig(level=logging.INFO,\n",
    "                    format='%(asctime)s %(levelname)s: %(message)s',\n",
    "                     datefmt='%Y-%m-%d %H:%M:%S',)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Get the version information of your package"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "logging.info('The version information:')\n",
    "logging.info(f'Python: {sys.version}')\n",
    "logging.info(f'PyTorch: {torch.__version__}')\n",
    "assert torch.cuda.is_available() == True, 'Please finish your GPU develop environment'"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## Load and Visualize the Data\n",
    "\n",
    "Downloading may take a few moments, and you should see your progress as the data is loading. You may also choose to change the `batch_size` if you want to load more data at a time.\n",
    "\n",
    "This cell will create DataLoaders for each of our datasets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torchvision import datasets\n",
    "import torchvision.transforms as transforms\n",
    "from torch.utils.data.dataset import Dataset\n",
    "\n",
    "# number of subprocesses to use for data loading\n",
    "num_workers = 0\n",
    "# how many samples per batch to load\n",
    "batch_size = 20\n",
    "\n",
    "# convert data to torch.FloatTensor\n",
    "transform = transforms.ToTensor()\n",
    "\n",
    "# choose the training and test datasets\n",
    "train_data = datasets.MNIST(root='data', train=True,\n",
    "                                   download=True, transform=transform)\n",
    "test_data = datasets.MNIST(root='data', train=False,\n",
    "                                  download=True, transform=transform)\n",
    "\n",
    "# prepare data loaders\n",
    "def classify_label(dataset, num_classes):\n",
    "    list_index = [[] for _ in range(num_classes)]\n",
    "    for idx, datum in enumerate(dataset):\n",
    "        list_index[datum[1]].append(idx)\n",
    "    return list_index\n",
    "\n",
    "def partition_train(list_label2indices: list, num_per_class: int):\n",
    "    random_state = np.random.RandomState(0)\n",
    "    list_label2indices_train = []\n",
    "    for indices in list_label2indices:\n",
    "        random_state.shuffle(indices)\n",
    "        list_label2indices_train.extend(indices[:num_per_class])\n",
    "    return list_label2indices_train\n",
    "\n",
    "class Indices2Dataset(Dataset):\n",
    "    def __init__(self, dataset):\n",
    "        self.dataset = dataset\n",
    "        self.indices = None\n",
    "\n",
    "    def load(self, indices: list):\n",
    "        self.indices = indices\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        idx = self.indices[idx]\n",
    "        image, label = self.dataset[idx]\n",
    "        return image, label\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.indices)\n",
    "\n",
    "#  sort train data by label\n",
    "list_label2indices = classify_label(dataset=train_data, num_classes=10)\n",
    "\n",
    "# how many samples per class to train\n",
    "list_train = partition_train(list_label2indices, 500)\n",
    "\n",
    "# prepare data loaders  \n",
    "indices2data = Indices2Dataset(train_data)\n",
    "indices2data.load(list_train)\n",
    "train_loader = torch.utils.data.DataLoader(indices2data, batch_size=batch_size, num_workers=num_workers, shuffle=True)\n",
    "test_loader = torch.utils.data.DataLoader(test_data, batch_size=batch_size, num_workers=num_workers, shuffle=True)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Visualize a Batch of Training Data\n",
    "\n",
    "The first step in a classification task is to take a look at the data, make sure it is loaded in correctly, then make any initial observations about patterns in that data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "    \n",
    "# obtain one batch of training images\n",
    "dataiter = iter(train_loader)\n",
    "images, labels = dataiter.next()\n",
    "images = images.numpy()\n",
    "\n",
    "# plot the images in the batch, along with the corresponding labels\n",
    "fig = plt.figure(figsize=(25, 4))\n",
    "for idx in np.arange(20):\n",
    "    ax = fig.add_subplot(2, 20//2, idx+1, xticks=[], yticks=[])\n",
    "    ax.imshow(np.squeeze(images[idx]), cmap='gray')\n",
    "    # print out the correct label for each image\n",
    "    # .item() gets the value contained in a Tensor\n",
    "    ax.set_title(str(labels[idx].item()))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### View an Image in More Detail"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "img = np.squeeze(images[1])\n",
    "\n",
    "fig = plt.figure(figsize = (12,12)) \n",
    "ax = fig.add_subplot(111)\n",
    "ax.imshow(img, cmap='gray')\n",
    "width, height = img.shape\n",
    "thresh = img.max()/2.5\n",
    "for x in range(width):\n",
    "    for y in range(height):\n",
    "        val = round(img[x][y],2) if img[x][y] !=0 else 0\n",
    "        ax.annotate(str(val), xy=(y,x),\n",
    "                    horizontalalignment='center',\n",
    "                    verticalalignment='center',\n",
    "                    color='white' if img[x][y]<thresh else 'black')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## Set random seed\n",
    "A random seed is used to ensure that results are reproducible. In other words, using this parameter makes sure that anyone who re-runs your code will get the exact same outputs. Reproducibility is an extremely important concept in data science and other fields. More details to read: [How to Use Random Seeds Effectively](https://towardsdatascience.com/how-to-use-random-seeds-effectively-54a4cd855a79)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "import os\n",
    "\n",
    "## give the number you like such as 2023\n",
    "seed_value = 2023\n",
    "\n",
    "np.random.seed(seed_value)\n",
    "random.seed(seed_value)\n",
    "os.environ['PYTHONHASHSEED'] = str(seed_value)\n",
    "\n",
    "torch.manual_seed(seed_value)     \n",
    "torch.cuda.manual_seed(seed_value)     \n",
    "torch.cuda.manual_seed_all(seed_value)   \n",
    "torch.backends.cudnn.deterministic = True\n",
    "logging.info(f\"tha value of the random seed: {seed_value}\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## Define the Network Architecture (30 marks)\n",
    "\n",
    "* Input: a 784-dim Tensor of pixel values for each image.\n",
    "* Output: a 10-dim Tensor of number of classes that indicates the class scores for an input image. \n",
    "\n",
    "You need to implement three models:\n",
    "1. a vanilla multi-layer perceptron. (10 marks)\n",
    "2. a multi-layer perceptron with regularization (dropout or L2 or both). (10 marks)\n",
    "3. the corresponding loss functions and optimizers. (10 marks)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Build model_1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Define the MLP architecture\n",
    "class VanillaMLP(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(VanillaMLP, self).__init__()\n",
    "        \n",
    "        # implement your codes here\n",
    "        \n",
    "\n",
    "\n",
    "    def forward(self, x):\n",
    "        # flatten image input\n",
    "        x = x.view(-1, 28 * 28)\n",
    "\n",
    "        # implement your codes here\n",
    "        \n",
    "        \n",
    "        \n",
    "        return x\n",
    "\n",
    "# initialize the MLP\n",
    "model_1 = VanillaMLP()\n",
    "\n",
    "# specify loss function\n",
    "# implement your codes here\n",
    "loss_model_1 = \n",
    "\n",
    "# specify your optimizer\n",
    "# implement your codes here\n",
    "optimizer_model_1 = "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Build model_2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Define the MLP architecture\n",
    "class RegularizedMLP(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(RegularizedMLP, self).__init__()\n",
    "        \n",
    "        # implement your codes here\n",
    "        \n",
    "\n",
    "    def forward(self, x):\n",
    "        # flatten image input\n",
    "        x = x.view(-1, 28 * 28)\n",
    "\n",
    "        # implement your codes here\n",
    "        \n",
    "        \n",
    "        return x\n",
    "\n",
    "\n",
    "# initialize the MLP\n",
    "model_2 = RegularizedMLP()\n",
    "\n",
    "# specify loss function\n",
    "# implement your codes here\n",
    "loss_model_2 = \n",
    "\n",
    "# specify your optimizer\n",
    "# implement your codes here\n",
    "optimizer_model_2 = "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## Train the Network (30 marks)\n",
    "\n",
    "Train your models in the following two cells.\n",
    "\n",
    "The following loop trains for 30 epochs; feel free to change this number. For now, we suggest somewhere between 20-50 epochs. As you train, take a look at how the values for the training loss decrease over time. We want it to decrease while also avoiding overfitting the training data. \n",
    "\n",
    "We will introduce some metrics of classification tasks and you will learn how implement these metrics with scikit-learn.\n",
    "\n",
    "There are supply some references for you to learn: [evaluation_metrics_spring2020](https://cs229.stanford.edu/section/evaluation_metrics_spring2020.pdf).\n",
    "\n",
    "In training processing, we will use accuracy,  Area Under ROC and top k accuracy.\n",
    "\n",
    "**The key parts in the training process are left for you to implement.**"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train model_1\n",
    "#### Train model_1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import scikit-learn packages\n",
    "# please use the function imported from scikit-learn to metric the process of training of the model\n",
    "from sklearn.metrics import accuracy_score,roc_auc_score, top_k_accuracy_score\n",
    "# number of epochs to train the model\n",
    "n_epochs = 20  # suggest training between 20-50 epochs\n",
    "\n",
    "model_1.train() # prep model for training\n",
    "\n",
    "train_loss_list = []\n",
    "train_acc_list = []\n",
    "train_auc_list = []\n",
    "train_top_k_acc_list = []\n",
    "\n",
    "\n",
    "# GPU check\n",
    "logging.info(f'GPU is available: {torch.cuda.is_available()}')\n",
    "if torch.cuda.is_available():\n",
    "    gpu_num = torch.cuda.device_count()\n",
    "    logging.info(f\"Train model on {gpu_num} GPUs:\")\n",
    "    for i in range(gpu_num):\n",
    "        print('\\t GPU {}.: {}'.format(i,torch.cuda.get_device_name(i)))\n",
    "    model_1 = model_1.cuda()\n",
    "\n",
    "for epoch in range(n_epochs):\n",
    "    # monitor training loss\n",
    "    train_loss = 0.0\n",
    "    pred_array = None\n",
    "    label_array =  None\n",
    "    \n",
    "    one_hot_label_matrix = None\n",
    "    pred_matrix = None\n",
    "    \n",
    "\n",
    "    for data, label in train_loader:\n",
    "        data = data.cuda()\n",
    "        label = label.cuda()\n",
    "        # implement your code here\n",
    "        \n",
    "\n",
    "        # finish the the computation of variables of metric\n",
    "        # implement your codes here\n",
    "        if pred_matrix is None:\n",
    "            pred_matrix = \n",
    "        else:\n",
    "            pred_matrix = np.concatenate()\n",
    "\n",
    "        if one_hot_label_matrix is None:\n",
    "            one_hot_label_matrix = \n",
    "        else:\n",
    "            one_hot_label_matrix = np.concatenate()\n",
    "\n",
    "        pred = torch.argmax(pred, axis=1)\n",
    "        if pred_array is None:\n",
    "            pred_array = \n",
    "        else:\n",
    "            pred_array = np.concatenate()\n",
    "\n",
    "        if label_array is None:\n",
    "            label_array = \n",
    "        else:\n",
    "            label_array = np.concatenate()\n",
    "\n",
    "        \n",
    "\n",
    "\n",
    "        \n",
    "        \n",
    "    # print training statistics \n",
    "    # read the API document at https://scikit-learn.org/stable/modules/classes.html#module-sklearn.metrics to finish your code\n",
    "    # don't craft your own code\n",
    "    # calculate average loss and accuracy over an epoch\n",
    "    \n",
    "    top_k = 3\n",
    "    train_loss = train_loss / len(train_loader.dataset)\n",
    "    train_acc = 100. * accuracy_score(label_array, pred_array)\n",
    "    train_auc = roc_auc_score(one_hot_label_matrix, pred_matrix , multi_class='ovo')\n",
    "    top_k_acc = top_k_accuracy_score(label_array, pred_matrix , k=top_k,)\n",
    "    # append the value of the metric to the list\n",
    "    train_loss_list.append(train_loss.cpu().detach().numpy())\n",
    "    train_acc_list.append(train_acc)\n",
    "    train_auc_list.append(train_auc)\n",
    "    train_top_k_acc_list.append(top_k_acc)\n",
    "    \n",
    "    logging.info('Epoch: {} \\tTraining Loss: {:.6f} \\tTraining Acc: {:.2f}% \\t top {} Acc: {:.2f}% \\t AUC Score: {:.4f}'.format(\n",
    "        epoch+1, \n",
    "        train_loss,\n",
    "        train_acc,\n",
    "        top_k,\n",
    "        top_k_acc,\n",
    "        train_auc,\n",
    "        ))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Visualize the training process of the model_1\n",
    "Please read the [document](https://matplotlib.org/stable/tutorials/introductory/pyplot.html#sphx-glr-tutorials-introductory-pyplot-py) to finish the training process visualization.\n",
    "For more information, please refer to the [document](https://matplotlib.org/stable/tutorials/index.html)\n",
    "##### Plot the change of the loss of model_1 during training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "epochs_list = list(range(1,n_epochs+1))\n",
    "plt.figure(figsize=(20, 8))\n",
    "plt.plot(epochs_list, train_loss_list)\n",
    "plt.title('Model_1 loss')\n",
    "plt.ylabel('Loss')\n",
    "plt.xlabel('Epoch')\n",
    "plt.legend(['Train'], loc='upper right')\n",
    "plt.show()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Plot the change of the accuracy of model_1 during training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(20, 8))\n",
    "plt.plot(epochs_list, train_acc_list)\n",
    "plt.title('Model_1 accuracy')\n",
    "plt.ylabel('accuracy')\n",
    "plt.xlabel('Epoch')\n",
    "plt.legend(['Train'], loc='upper right')\n",
    "plt.show()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Plot the change of the AUC Score of model_1 during training\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(20, 8))\n",
    "plt.plot(epochs_list, train_auc_list)\n",
    "plt.title('Model_1 auc')\n",
    "plt.ylabel('Auc')\n",
    "plt.xlabel('Epoch')\n",
    "plt.legend(['Train'], loc='upper right')\n",
    "plt.show()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train model_2\n",
    "\n",
    "#### Train model_2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import scikit-learn packages\n",
    "# please use the function imported from scikit-learn to metric the process of training of the model\n",
    "from sklearn.metrics import accuracy_score,roc_auc_score, top_k_accuracy_score\n",
    "# number of epochs to train the model\n",
    "n_epochs = 20  # suggest training between 20-50 epochs\n",
    "\n",
    "model_1.train() # prep model for training\n",
    "\n",
    "train_loss_list = []\n",
    "train_acc_list = []\n",
    "train_auc_list = []\n",
    "train_top_k_acc_list = []\n",
    "\n",
    "\n",
    "# GPU check\n",
    "logging.info(f'GPU is available: {torch.cuda.is_available()}')\n",
    "if torch.cuda.is_available():\n",
    "    gpu_num = torch.cuda.device_count()\n",
    "    logging.info(f\"Train model on {gpu_num} GPUs:\")\n",
    "    for i in range(gpu_num):\n",
    "        print('\\t GPU {}.: {}'.format(i,torch.cuda.get_device_name(i)))\n",
    "    model_1 = model_1.cuda()\n",
    "\n",
    "for epoch in range(n_epochs):\n",
    "    # monitor training loss\n",
    "    train_loss = 0.0\n",
    "    pred_array = None\n",
    "    label_array =  None\n",
    "    \n",
    "    one_hot_label_matrix = None\n",
    "    pred_matrix = None\n",
    "    \n",
    "\n",
    "    for data, label in train_loader:\n",
    "        data = data.cuda()\n",
    "        label = label.cuda()\n",
    "        # implement your code here\n",
    "        \n",
    "\n",
    "        # finish the the computation of variables of metric\n",
    "        # implement your codes here\n",
    "        if pred_matrix is None:\n",
    "            pred_matrix = \n",
    "        else:\n",
    "            pred_matrix = np.concatenate()\n",
    "\n",
    "        if one_hot_label_matrix is None:\n",
    "            one_hot_label_matrix = \n",
    "        else:\n",
    "            one_hot_label_matrix = np.concatenate()\n",
    "\n",
    "        pred = torch.argmax(pred, axis=1)\n",
    "        if pred_array is None:\n",
    "            pred_array = \n",
    "        else:\n",
    "            pred_array = np.concatenate()\n",
    "\n",
    "        if label_array is None:\n",
    "            label_array = \n",
    "        else:\n",
    "            label_array = np.concatenate()\n",
    "\n",
    "        \n",
    "\n",
    "\n",
    "        \n",
    "        \n",
    "    # print training statistics \n",
    "    # read the API document at https://scikit-learn.org/stable/modules/classes.html#module-sklearn.metrics to finish your code\n",
    "    # don't craft your own code\n",
    "    # calculate average loss and accuracy over an epoch\n",
    "    \n",
    "    top_k = 3\n",
    "    train_loss = train_loss / len(train_loader.dataset)\n",
    "    train_acc = 100. * accuracy_score(label_array, pred_array)\n",
    "    train_auc = roc_auc_score(one_hot_label_matrix, pred_matrix , multi_class='ovo')\n",
    "    top_k_acc = top_k_accuracy_score(label_array, pred_matrix , k=top_k,)\n",
    "    # append the value of the metric to the list\n",
    "    train_loss_list.append(train_loss.cpu().detach().numpy())\n",
    "    train_acc_list.append(train_acc)\n",
    "    train_auc_list.append(train_auc)\n",
    "    train_top_k_acc_list.append(top_k_acc)\n",
    "    \n",
    "    logging.info('Epoch: {} \\tTraining Loss: {:.6f} \\tTraining Acc: {:.2f}% \\t top {} Acc: {:.2f}% \\t AUC Score: {:.4f}'.format(\n",
    "        epoch+1, \n",
    "        train_loss,\n",
    "        train_acc,\n",
    "        top_k,\n",
    "        top_k_acc,\n",
    "        train_auc,\n",
    "        ))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Visualize the training process of the model_2\n",
    "Please read the [document](https://matplotlib.org/stable/tutorials/introductory/pyplot.html#sphx-glr-tutorials-introductory-pyplot-py) to finish the training process visualization.\n",
    "For more information, please refer to the [document](https://matplotlib.org/stable/tutorials/index.html)\n",
    "##### Plot the change of the loss of model_2 during training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "epochs_list = list(range(1,n_epochs+1))\n",
    "plt.figure(figsize=(20, 8))\n",
    "plt.plot(epochs_list, train_loss_list)\n",
    "plt.title('Model_2 loss')\n",
    "plt.ylabel('Loss')\n",
    "plt.xlabel('Epoch')\n",
    "plt.legend(['Train'], loc='upper right')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Plot the change of the accuracy of model_2 during training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(20, 8))\n",
    "plt.plot(epochs_list, train_acc_list)\n",
    "plt.title('Model_2 accuracy')\n",
    "plt.ylabel('accuracy')\n",
    "plt.xlabel('Epoch')\n",
    "plt.legend(['Train'], loc='upper right')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Plot the change of the AUC Score of model_1 during training\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(20, 8))\n",
    "plt.plot(epochs_list, train_auc_list)\n",
    "plt.title('Model_2 auc')\n",
    "plt.ylabel('Auc')\n",
    "plt.xlabel('Epoch')\n",
    "plt.legend(['Train'], loc='upper right')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## Test the Trained Network (20 marks)\n",
    "\n",
    "Test the performance of trained models on test data. Except the total test accuracy, you should calculate the accuracy for each class.\n",
    "\n",
    "About metrics, in test processing, we will use accuracy, top k accuracy, precision, recall, f1-score and confusion matrix. \n",
    "\n",
    "Besides, we will visualize the confusion matrix.\n",
    "\n",
    "Last but not least, we will compare your implementation of function to compute accuracy with the implementation of scikit-learn."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## define your implementation of function to compute accuracy\n",
    "def accuracy_score_manual(label_array, pred_array):\n",
    "    # implement your codes here"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test model_1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import classification_report,ConfusionMatrixDisplay\n",
    "# initialize lists to monitor test loss and accuracy\n",
    "test_loss = 0.0\n",
    "\n",
    "pred_array = None\n",
    "label_array =  None\n",
    "\n",
    "one_hot_label_matrix = None\n",
    "pred_matrix = None\n",
    "\n",
    "model_1.eval() # prep model for *evaluation*\n",
    "\n",
    "for data, label in test_loader:\n",
    "    data = data.cuda()\n",
    "    label = label.cuda()\n",
    "    # implement your code here\n",
    "    pred = \n",
    "    test_loss = \n",
    "\n",
    "    if pred_matrix is None:\n",
    "        pred_matrix = \n",
    "    else:\n",
    "        pred_matrix = \n",
    "\n",
    "    if one_hot_label_matrix is None:\n",
    "        one_hot_label_matrix = \n",
    "    else:\n",
    "        one_hot_label_matrix = \n",
    "    pred = torch.argmax(pred, axis=1)\n",
    "    \n",
    "    if pred_array is None:\n",
    "        pred_array = \n",
    "    else:\n",
    "        pred_array = \n",
    "\n",
    "    if label_array is None:\n",
    "        label_array = \n",
    "    else:\n",
    "        label_array = \n",
    "# calculate and print avg test loss\n",
    "test_loss = test_loss / len(test_loader.dataset)\n",
    "test_acc = accuracy_score(label_array, pred_array)\n",
    "test_auc = roc_auc_score(one_hot_label_matrix, pred_matrix , multi_class='ovo')\n",
    "test_top_k3_acc = top_k_accuracy_score(label_array, pred_matrix , k=3)\n",
    "test_top_k5_acc = top_k_accuracy_score(label_array, pred_matrix , k=5)\n",
    "\n",
    "logging.info('Test Loss: {:.6f}'.format(test_loss))\n",
    "logging.info('Test Accuracy: {:.6f}'.format(test_acc))\n",
    "logging.info('Test top 3 Accuracy: {:.6f}'.format(test_top_k3_acc ))\n",
    "logging.info('Test top 5 Accuracy: {:.6f}'.format(test_top_k5_acc ))\n",
    "logging.info('The classification report of test for model_1')\n",
    "print(classification_report(label_array, pred_array))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ConfusionMatrixDisplay.from_predictions(label_array,pred_array)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## compare your implementation of function to compute accuracy with the implementation of scikit-learn.\n",
    "your_test_acc = accuracy_score_manual(label_array, pred_array)\n",
    "assert abs(your_test_acc - test_acc) < 1e-5 , 'Please check your implementation of function to compute accuracy'"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test model_2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import classification_report,ConfusionMatrixDisplay\n",
    "# initialize lists to monitor test loss and accuracy\n",
    "test_loss = 0.0\n",
    "\n",
    "pred_array = None\n",
    "label_array =  None\n",
    "\n",
    "one_hot_label_matrix = None\n",
    "pred_matrix = None\n",
    "\n",
    "model_2.eval() # prep model for *evaluation*\n",
    "\n",
    "for data, label in test_loader:\n",
    "    data = data.cuda()\n",
    "    label = label.cuda()\n",
    "    # implement your code here\n",
    "    pred = \n",
    "    test_loss = \n",
    "\n",
    "    if pred_matrix is None:\n",
    "        pred_matrix = \n",
    "    else:\n",
    "        pred_matrix = \n",
    "\n",
    "    if one_hot_label_matrix is None:\n",
    "        one_hot_label_matrix = \n",
    "    else:\n",
    "        one_hot_label_matrix = \n",
    "    pred = torch.argmax(pred, axis=1)\n",
    "    \n",
    "    if pred_array is None:\n",
    "        pred_array = \n",
    "    else:\n",
    "        pred_array = \n",
    "\n",
    "    if label_array is None:\n",
    "        label_array = \n",
    "    else:\n",
    "        label_array = \n",
    "# calculate and print avg test loss\n",
    "test_loss = test_loss / len(test_loader.dataset)\n",
    "test_acc = accuracy_score(label_array, pred_array)\n",
    "test_auc = roc_auc_score(one_hot_label_matrix, pred_matrix , multi_class='ovo')\n",
    "test_top_k3_acc = top_k_accuracy_score(label_array, pred_matrix , k=3)\n",
    "test_top_k5_acc = top_k_accuracy_score(label_array, pred_matrix , k=5)\n",
    "\n",
    "logging.info('Test Loss: {:.6f}'.format(test_loss))\n",
    "logging.info('Test Accuracy: {:.6f}'.format(test_acc))\n",
    "logging.info('Test top 3 Accuracy: {:.6f}'.format(test_top_k3_acc ))\n",
    "logging.info('Test top 5 Accuracy: {:.6f}'.format(test_top_k5_acc ))\n",
    "logging.info('The classification report of test for model_1')\n",
    "print(classification_report(label_array, pred_array))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ConfusionMatrixDisplay.from_predictions(label_array,pred_array)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## compare your implementation of function to compute accuracy with the implementation of scikit-learn.\n",
    "your_test_acc = accuracy_score_manual(label_array, pred_array)\n",
    "assert abs(your_test_acc - test_acc) < 1e-5 , 'Please check your implementation of function to compute accuracy'"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## Analyze Your Result (20 marks)\n",
    "Compare the performance of your models with the following analysis. Both English and Chinese answers are acceptable.\n",
    "1. Does your vanilla MLP overfit to the training data? (5 marks)\n",
    "\n",
    "Answer:\n",
    "\n",
    "2. If yes, how do you observe it? If no, why? (5 marks)\n",
    "\n",
    "Answer:\n",
    "\n",
    "3. Is regularized model help prevent overfitting? (5 marks)\n",
    "\n",
    "Answer:\n",
    "\n",
    "4. Generally compare the performance of two models. (5 marks)\n",
    "\n",
    "Answer:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
